{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f752b49",
   "metadata": {},
   "source": [
    "## üéØ Pregunta de negocio  \n",
    "**¬øC√≥mo puede Mercado Libre identificar a los sellers m√°s relevantes y segmentarlos para dise√±ar estrategias comerciales personalizadas?**\n",
    "\n",
    "üß† **Hip√≥tesis inicial:**  \n",
    "Los sellers con **alto stock**, **muchas publicaciones** y **cero productos reacondicionados** tienden a ser m√°s relevantes para el negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d609cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "sys.path.append(\"C:/Users/dario/Documents/worksapce/sellers_analitycs_meli\")\n",
    "\n",
    "from meli_insight_engine.llm.prompts.templates import BASIC_RECOMMENDATION_PROMPT_JSON, BASIC_RECOMMENDATION_PROMPT_HIPOTESIS\n",
    "from meli_insight_engine.llm.agents.agent_template import TemplateAgent\n",
    "from meli_insight_engine.core import (\n",
    "    conectar_duckdb,\n",
    "    registrar_csvs_como_vistas,\n",
    "    verificar_vistas,\n",
    "    analisis_inicial_completo,\n",
    "    guardar_resultados_como_txt\n",
    ")\n",
    "import joblib, os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb222f01",
   "metadata": {},
   "source": [
    "# üß† Descubrimiento inicial del dataset con MAD-G\n",
    "\n",
    "Este notebook realiza una **revisi√≥n estructural y exploraci√≥n inicial** del archivo `df_challenge.csv`, en el contexto del challenge de segmentaci√≥n de sellers de Mercado Libre.\n",
    "\n",
    "üìç **Objetivo general:**\n",
    "Comprender la composici√≥n y calidad del dataset para dise√±ar una soluci√≥n de clusterizaci√≥n efectiva y alineada con necesidades comerciales.\n",
    "\n",
    "üìå **Lo que haremos en esta etapa:**\n",
    "- Analizar la estructura del dataset (columnas, tipos de datos, duplicados, nulos, constantes).\n",
    "- Detectar variables relevantes para caracterizar a los sellers.\n",
    "- Evaluar posibles problemas de calidad de datos que deban corregirse o imputarse.\n",
    "- Generar **hip√≥tesis de negocio iniciales** con ayuda de un modelo de lenguaje (LLM), a partir de la observaci√≥n de los datos.\n",
    "  \n",
    "üß© **¬øQu√© estamos construyendo?**\n",
    "Una herramienta anal√≠tica que combina la exploraci√≥n de datos tradicional con un asistente de IA (LLM), capaz de:\n",
    "- Proponer agrupaciones l√≥gicas de vendedores.\n",
    "- Sugerir estrategias de segmentaci√≥n.\n",
    "- Enriquecer el entendimiento de los datos con razonamiento automatizado.\n",
    "\n",
    "Esta exploraci√≥n ser√° la base para la ingenier√≠a de features y el modelado posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fc78b",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuraci√≥n del entorno y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4127b",
   "metadata": {},
   "source": [
    "### Analisis de datos para levantar hipotesis usando LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e61fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear conexi√≥n a DuckDB\n",
    "con = conectar_duckdb()\n",
    "\n",
    "# Ruta a tu carpeta con archivos .csv de prueba (aseg√∫rate de que exista y tenga al menos un .csv)\n",
    "folder_path = \"../data/\"\n",
    "# Registrar vistas\n",
    "registrar_csvs_como_vistas(con, folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21426ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vistas registradas:\n",
      "                        table_name\n",
      "0     data.cluster_stats_empiricas\n",
      "1           data.df_challenge_meli\n",
      "2  data.df_challenge_meli_clusters\n",
      "3    data.df_challenge_meli_limpio\n",
      "4                data.pca_loadings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n",
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n",
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n",
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n",
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n",
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n",
      "C:\\Users/dario/Documents/worksapce/sellers_analitycs_meli\\meli_insight_engine\\core\\inspector.py:359: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fechas_parseadas = pd.to_datetime(df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en: ../data/outputs_prompts/inspector_stats.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Verificar vistas\n",
    "print(\"‚úÖ Vistas registradas:\")\n",
    "print(verificar_vistas(con))\n",
    "\n",
    "# Reemplaza con el nombre real del archivo sin .csv y sin guiones (los guiones se vuelven guiones bajos)\n",
    "nombre_tabla = \"data.df_challenge_meli\"# Ejemplo: si el archivo se llama \"ventas-julio.csv\", usa \"data.ventas_julio\"\n",
    "\n",
    "resultados = analisis_inicial_completo(con, \"data.df_challenge_meli\")\n",
    "guardar_resultados_como_txt(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6469b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4421c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dario\\anaconda3\\envs\\meli_challenge\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\dario\\anaconda3\\envs\\meli_challenge\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/outputs_prompts\\BASIC_RECOMMENDATION_PROMPT_JSON.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta del archivo .txt\n",
    "ruta_txt = \"../data/outputs_prompts/inspector_stats.txt\"\n",
    "\n",
    "# Leer contenido del archivo\n",
    "with open(ruta_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    texto = f.read()\n",
    "\n",
    "    # Instanciar el agente con el template y el texto le√≠do\n",
    "    agent = TemplateAgent(prompt_template=BASIC_RECOMMENDATION_PROMPT_JSON,template_name= \"BASIC_RECOMMENDATION_PROMPT_JSON\" )\n",
    "\n",
    "# Ejecutar\n",
    "respuesta = agent.run(input_path=ruta_txt)\n",
    "\n",
    "# Mostrar respuesta\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3f786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/outputs_prompts\\BASIC_RECOMMENDATION_PROMPT_HIPOTESIS.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ruta del archivo .txt\n",
    "ruta_txt = \"../data/outputs_prompts/BASIC_RECOMMENDATION_PROMPT_JSON.txt\"\n",
    "\n",
    "# Leer contenido del archivo\n",
    "with open(ruta_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    texto = f.read()\n",
    "\n",
    "    # Instanciar el agente con el template y el texto le√≠do\n",
    "    agent = TemplateAgent(prompt_template=BASIC_RECOMMENDATION_PROMPT_HIPOTESIS,template_name= \"BASIC_RECOMMENDATION_PROMPT_HIPOTESIS\" )\n",
    "\n",
    "# Ejecutar\n",
    "respuesta = agent.run(input_path=ruta_txt)\n",
    "\n",
    "# Mostrar respuesta\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25de75",
   "metadata": {},
   "source": [
    "#### resultados de MDA-G (models for data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605db7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **Reporte de Comprensi√≥n Inicial del Dataset**\n",
       "\n",
       "---\n",
       "\n",
       "#### **1. Estructura B√°sica**\n",
       "- **Total registros**: 185,250  \n",
       "- **Total variables**: 14  \n",
       "- **Variables clave identificadas**:  \n",
       "  - **[Num√©rica Continua] `price`**: Precio de venta con valores extremos (hasta 4.7B) y media en 37,015.  \n",
       "  - **[Num√©rica Discreta] `stock`**: Inventario altamente sesgado (moda = 1, max = 99,999).  \n",
       "  - **[Categ√≥rica Ordinal] `seller_reputation`**: Jerarqu√≠a de reputaci√≥n (newbie ‚Üí platinum) con dominio de vendedores platinum (37.6%).  \n",
       "  - **[Categ√≥rica Nominal] `logistic_type`**: Log√≠stica dominada por \"XD\" (63%, propio de MercadoLibre).  \n",
       "  - **[Booleana] `is_refurbished`**: Desbalance extremo (0.4% refurbished).  \n",
       "\n",
       "---\n",
       "\n",
       "#### **2. Hallazgos de Calidad**  \n",
       "- **`price`**:  \n",
       "  - **Tipo de problema**: Outliers extremos (max = 4.7B vs. media = 37K).  \n",
       "  - **Severidad**: Alta (distorsiona estad√≠sticas).  \n",
       "  - **Acci√≥n**: Winsorizaci√≥n al 99.9% + transformaci√≥n logar√≠tmica.  \n",
       "\n",
       "- **`regular_price`**:  \n",
       "  - **Tipo de problema**: 73% nulos + inconsistencia con `price` (valores frecuentes repetidos).  \n",
       "  - **Severidad**: Media-Alta (afecta an√°lisis de descuentos).  \n",
       "  - **Acci√≥n**: Imputar con `price` * 1.2 (default) o eliminar.  \n",
       "\n",
       "- **`seller_reputation`**:  \n",
       "  - **Tipo de problema**: 1.3% nulos + jerarqu√≠a ordinal no codificada.  \n",
       "  - **Severidad**: Media.  \n",
       "  - **Acci√≥n**: Codificaci√≥n ordinal (newbie=1, platinum=5).  \n",
       "\n",
       "- **`is_refurbished`**:  \n",
       "  - **Tipo de problema**: Desbalance (735 vs. 184K).  \n",
       "  - **Severidad**: Alta para modelos predictivos.  \n",
       "  - **Acci√≥n**: Oversampling (target ratio = 10%).  \n",
       "\n",
       "- **`tim_day`**:  \n",
       "  - **Tipo de problema**: Constante (√∫nico valor: 2024-08-01).  \n",
       "  - **Severidad**: Baja (sin impacto anal√≠tico).  \n",
       "  - **Acci√≥n**: Eliminar.  \n",
       "\n",
       "---\n",
       "\n",
       "#### **3. Relaciones Potenciales**  \n",
       "- **`seller_reputation` ‚Üî `price`**: ¬øVendedores premium fijan precios m√°s altos? Validar con ANOVA o boxplots por tier.  \n",
       "- **`logistic_type` ‚Üî `stock`**: ¬øLog√≠stica \"XD\" tiene mejor gesti√≥n de inventario? Analizar con medianas agrupadas.  \n",
       "- **`category_id` ‚Üî `price`**: ¬øCategor√≠as espec√≠ficas tienen precios m√°s altos? Heatmap de precios medios por categor√≠a.  \n",
       "\n",
       "---\n",
       "\n",
       "#### **4. Recomendaciones para EDA**  \n",
       "- **Grupo 1 (Precios y Reputaci√≥n)**:  \n",
       "  - Variables: `price`, `regular_price`, `seller_reputation`.  \n",
       "  - Objetivo: Identificar estrategias de pricing por reputaci√≥n.  \n",
       "  - Transformaci√≥n: Winsorizar `price` + codificar ordinalmente reputaci√≥n.  \n",
       "\n",
       "- **Grupo 2 (Inventario y Log√≠stica)**:  \n",
       "  - Variables: `stock`, `logistic_type`, `categoria`.  \n",
       "  - Objetivo: Explorar eficiencia log√≠stica por categor√≠a.  \n",
       "  - Transformaci√≥n: Agrupar categor√≠as minoritarias.  \n",
       "\n",
       "---\n",
       "\n",
       "#### **5. Advertencias Clave**  \n",
       "- **Limitaci√≥n 1**: Outliers en `price` invalidan estad√≠sticas descriptivas actuales.  \n",
       "  - **Impacto**: Cualquier modelo sin tratamiento ser√° sesgado.  \n",
       "- **Limitaci√≥n 2**: Alta cardinalidad en `titulo` (174K √∫nicos).  \n",
       "  - **Acci√≥n**: Usar NLP b√°sico (ej: longitud de texto) o excluir.  \n",
       "\n",
       "---\n",
       "\n",
       "#### **6. Conclusi√≥n Ejecutiva**  \n",
       "- **Calidad del Dataset**: **Aceptable con deficiencias cr√≠ticas**.  \n",
       "  - **Fortalezas**: Jerarqu√≠as claras (reputaci√≥n), cobertura amplia (185K registros).  \n",
       "  - **Debilidades**: Outliers extremos, nulos en `regular_price`, desbalances.  \n",
       "- **Variables Prometedoras**:  \n",
       "  - `seller_reputation` y `price` para segmentaci√≥n.  \n",
       "  - `logistic_type` para an√°lisis operacional.  \n",
       "- **Riesgos Principales**:  \n",
       "  - Outliers no tratados invalidar√°n modelos.  \n",
       "  - Desbalance en `is_refurbished` requiere t√©cnicas especializadas.  \n",
       "- **Valor Potencial**:  \n",
       "  - Con transformaciones, el dataset permite an√°lisis de pricing, eficiencia log√≠stica y reputaci√≥n de vendedores.  \n",
       "\n",
       "--- \n",
       "\n",
       "**Nota Final**: Priorizar limpieza de outliers y codificaci√≥n ordinal antes de EDA avanzado."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Ruta al archivo externo (por ejemplo, en una carpeta docs o en el root)\n",
    "ruta_readme = \"../data/outputs_prompts/BASIC_RECOMMENDATION_PROMPT_HIPOTESIS.txt\"\n",
    "\n",
    "# Leer y mostrar\n",
    "with open(ruta_readme, \"r\", encoding=\"utf-8\") as archivo:\n",
    "    contenido = archivo.read()\n",
    "\n",
    "display(Markdown(contenido))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bdb443",
   "metadata": {},
   "source": [
    "# Fetaured data pre segmentacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e817f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline guardado en models/pre_pipe.pkl\n",
      "  seller_nickname  categorias_distintas  log_price_avg  log_stock_avg  \\\n",
      "0      000631669c                   0.0       0.179097       0.199550   \n",
      "1      0007153bca                   0.0      -0.251401       0.546386   \n",
      "2      000bee3c3b                   0.0      -0.394075      -0.675326   \n",
      "3      000df2bd02                   0.0       0.590278      -0.021600   \n",
      "4      000e27cea2                   1.0      -0.208310      -0.181308   \n",
      "\n",
      "   num_publicaciones  porc_descuento  proporcion_refurb  proporcion_usados  \\\n",
      "0                0.0             0.0                0.0                0.0   \n",
      "1                0.5             0.0                0.0                0.0   \n",
      "2                0.5             0.0                0.0                0.0   \n",
      "3                0.0             0.0                0.0                1.0   \n",
      "4                0.5             0.0                0.0                0.0   \n",
      "\n",
      "   rep_score  titulo_length_avg  \n",
      "0  -1.000000          -2.900763  \n",
      "1   0.000000           0.458015  \n",
      "2  -1.000000          -2.366412  \n",
      "3   0.000000          -1.984733  \n",
      "4   0.333333           0.458015  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Cargar el dataset original\n",
    "df = pd.read_csv('../data/df_challenge_meli.csv')\n",
    "\n",
    "# 2. Feature engineering inicial\n",
    "df['discount_pct'] = np.where(\n",
    "    df['regular_price'].isna() | (df['regular_price'] == 0),\n",
    "    0,\n",
    "    (df['regular_price'] - df['price']) / df['regular_price']\n",
    ")\n",
    "\n",
    "df['title_len'] = df['titulo'].astype(str).str.len()\n",
    "\n",
    "rep_map = {\n",
    "    \"green_platinum\": 5, \"green_gold\": 4, \"green_silver\": 4,\n",
    "    \"green\": 3, \"light_green\": 3, \"yellow\": 2,\n",
    "    \"orange\": 1, \"red\": 1, \"newbie\": 0\n",
    "}\n",
    "df['rep_score'] = df['seller_reputation'].map(rep_map).fillna(0)\n",
    "\n",
    "# 3. Agregaci√≥n a nivel seller\n",
    "seller = (\n",
    "    df.groupby('seller_nickname')\n",
    "      .agg(\n",
    "          num_publicaciones=('titulo', 'size'),\n",
    "          log_stock_avg=('stock', lambda s: np.log1p(s).mean()),\n",
    "          log_price_avg=('price', lambda s: np.log1p(s).mean()),\n",
    "          porc_descuento=('discount_pct', 'mean'),\n",
    "          categorias_distintas=('category_id', 'nunique'),\n",
    "          proporcion_usados=('condition', lambda s: (s == 'used').mean()),\n",
    "          proporcion_refurb=('is_refurbished', 'mean'), #validar el porque la imputacion de la media \n",
    "          rep_score=('rep_score', 'mean'),\n",
    "          titulo_length_avg=('title_len', 'mean')\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 4. Definir pipeline (imputaci√≥n + escalado robusto)\n",
    "num_cols = seller.columns.difference(['seller_nickname'])\n",
    "X = seller[num_cols]\n",
    "\n",
    "pre_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# Aplicar las transformaciones\n",
    "X_scaled = pre_pipe.fit_transform(X)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(pre_pipe, \"../models/pre_pipe.pkl\")\n",
    "print(\"‚úÖ Pipeline guardado en models/pre_pipe.pkl\")\n",
    "\n",
    "\n",
    "# 5. Persistir resultados en un DataFrame limpio\n",
    "df_final = pd.DataFrame(X_scaled, columns=num_cols)\n",
    "df_final.insert(0, 'seller_nickname', seller['seller_nickname'])\n",
    "\n",
    "# Guardar dataset limpio y transformado\n",
    "df_final.to_csv('../data/df_challenge_meli_limpio.csv', index=False)\n",
    "\n",
    "# Confirmaci√≥n visual\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e420413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meli_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
